{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "path_labels_lifecycle = 'labels_lifecycle.json'\n",
    "folder = os.path.join(\"..\", \"0_dataset\")\n",
    "log_files = [['label_syslog_disk_wipe.csv', 1],\n",
    "               ['label_syslog_end_point_dos.csv', 4],\n",
    "               ['label_syslog_mirai.csv', 0],\n",
    "               ['label_syslog_ransomware.csv', 2],\n",
    "               ['label_syslog_resource_hijacking.csv', 3]]\n",
    "merged_list = ['results_T.csv', 'results_A.csv', 'results_L.csv', 'results_A+L.csv', 'results_A+T.csv', 'results_L+T.csv', 'results_A+L+T.csv']\n",
    "# merged_list = ['results_A+L+T.csv']\n",
    "folder_lifecycle = 'lifecycle'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get start and end time for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1673433290.0, 1673434411.0, 1], [1673439558.0, 1673440994.0, 4], [1673430856.0, 1673432522.0, 0], [1673435423.0, 1673436706.0, 2], [1673437131.0, 1673438383.0, 3]]\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "for file, label in log_files:\n",
    "    df_tmp = pd.read_csv(os.path.join(folder, 'syslog', file))\n",
    "    time_list.append([df_tmp['Timestamp'].iloc[0], df_tmp['Timestamp'].iloc[-1], label])\n",
    "    \n",
    "print(time_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequences Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label:0 t_start:1673430856.0, t_end:1673432522.0\n",
      "results_T.csv: start:1673430856.0 end:1673432522.0 len:1656\n",
      "results_A.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "results_L.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "results_A+L.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "results_A+T.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "results_L+T.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "results_A+L+T.csv: start:1673430856.0 end:1673432522.0 len:1667\n",
      "\n",
      "label:1 t_start:1673433290.0, t_end:1673434411.0\n",
      "results_T.csv: start:1673433290.0 end:1673434411.0 len:945\n",
      "results_A.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "results_L.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "results_A+L.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "results_A+T.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "results_L+T.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "results_A+L+T.csv: start:1673433290.0 end:1673434411.0 len:1122\n",
      "\n",
      "label:2 t_start:1673435423.0, t_end:1673436706.0\n",
      "results_T.csv: start:1673435423.0 end:1673436706.0 len:1105\n",
      "results_A.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "results_L.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "results_A+L.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "results_A+T.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "results_L+T.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "results_A+L+T.csv: start:1673435423.0 end:1673436706.0 len:1284\n",
      "\n",
      "label:3 t_start:1673437131.0, t_end:1673438383.0\n",
      "results_T.csv: start:1673437131.0 end:1673438383.0 len:1103\n",
      "results_A.csv: start:1673437131.0 end:1673438383.0 len:1253\n",
      "results_L.csv: start:1673437131.0 end:1673438383.0 len:1232\n",
      "results_A+L.csv: start:1673437131.0 end:1673438383.0 len:1253\n",
      "results_A+T.csv: start:1673437131.0 end:1673438383.0 len:1253\n",
      "results_L+T.csv: start:1673437131.0 end:1673438383.0 len:1253\n",
      "results_A+L+T.csv: start:1673437131.0 end:1673438383.0 len:1253\n",
      "\n",
      "label:4 t_start:1673439558.0, t_end:1673440994.0\n",
      "results_T.csv: start:1673439558.0 end:1673440994.0 len:1156\n",
      "results_A.csv: start:1673439558.0 end:1673440994.0 len:1437\n",
      "results_L.csv: start:1673439558.0 end:1673440994.0 len:1408\n",
      "results_A+L.csv: start:1673439558.0 end:1673440994.0 len:1437\n",
      "results_A+T.csv: start:1673439558.0 end:1673440994.0 len:1437\n",
      "results_L+T.csv: start:1673439558.0 end:1673440994.0 len:1437\n",
      "results_A+L+T.csv: start:1673439558.0 end:1673440994.0 len:1437\n",
      "<bound method DataFrame.info of                                             lifecycle Label\n",
      "0   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     0\n",
      "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...     0\n",
      "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...     0\n",
      "4   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "5   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "6   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "7   [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     1\n",
      "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     1\n",
      "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     1\n",
      "11  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "12  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "13  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "14  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "15  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...     2\n",
      "16  [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...     2\n",
      "17  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...     2\n",
      "18  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "19  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "20  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "21  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "22  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...     3\n",
      "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     3\n",
      "24  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...     3\n",
      "25  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "26  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "27  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "28  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "29  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...     4\n",
      "30  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     4\n",
      "31  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...     4\n",
      "32  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "33  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "34  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4>\n",
      "<bound method DataFrame.info of                                             lifecycle Label\n",
      "0   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "1   [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     0\n",
      "2   [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...     0\n",
      "3   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...     0\n",
      "4   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "5   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "6   [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...     0\n",
      "7   [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "8   [6, 0, 0, 0, 6, 6, 6, 0, 0, 0, 6, 0, 6, 0, 0, ...     1\n",
      "9   [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...     1\n",
      "10  [1, 0, 0, 1, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 14...     1\n",
      "11  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "12  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "13  [1, 0, 0, 1, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 14...     1\n",
      "14  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "15  [6, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, ...     2\n",
      "16  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     2\n",
      "17  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     2\n",
      "18  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "19  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "20  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "21  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "22  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, ...     3\n",
      "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...     3\n",
      "24  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...     3\n",
      "25  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "26  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "27  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...     3\n",
      "28  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "29  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, ...     4\n",
      "30  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...     4\n",
      "31  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     4\n",
      "32  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "33  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "34  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4>\n",
      "<bound method DataFrame.info of                                            lifecycle Label\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "1  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     1\n",
      "2  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...     2\n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     3\n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4>\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(columns=['lifecycle', 'Label'])\n",
    "df_test['lifecycle'] = df_test['lifecycle'].astype('object')\n",
    "df_train = pd.DataFrame(columns=['lifecycle', 'Label'])\n",
    "df_train['lifecycle'] = df_train['lifecycle'].astype('object')\n",
    "df_test['lifecycle'] = df_test['lifecycle'].astype('object')\n",
    "df_pattern = pd.DataFrame(columns=['lifecycle', 'Label'])\n",
    "df_pattern['lifecycle'] = df_pattern['lifecycle'].astype('object')\n",
    "\n",
    "# get label\n",
    "with open(path_labels_lifecycle, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    for label, name in data[1:]:\n",
    "        isfind = False\n",
    "        for start, end, label_time in time_list:\n",
    "            # print(f'label:{label}, label_time:{label_time}')\n",
    "            if int(label) == label_time:\n",
    "                t_start = start\n",
    "                t_end = end\n",
    "                isfind = True\n",
    "                print(f'\\nlabel:{label} t_start:{t_start}, t_end:{t_end}')\n",
    "                break\n",
    "        \n",
    "        if isfind == False:\n",
    "            continue\n",
    "        \n",
    "        # get merged sequences\n",
    "        def preprocess_seq(df_tmp, label, ispred):\n",
    "            if ispred:\n",
    "                seq = df_tmp.loc[((df_tmp['TIMESTAMP'] >= t_start) & (df_tmp['TIMESTAMP'] <= t_end)), 'pred'].tolist()\n",
    "            else:\n",
    "                seq = df_tmp.loc[((df_tmp['TIMESTAMP'] >= t_start) & (df_tmp['TIMESTAMP'] <= t_end)), 'label'].tolist()\n",
    "            while seq and seq[0] == 0:\n",
    "                seq.pop(0)\n",
    "            while seq and seq[-1] == 0:\n",
    "                seq.pop()\n",
    "            return pd.Series([seq, label], index=['lifecycle', 'Label'])\n",
    "        \n",
    "        for merged_res in merged_list:\n",
    "            df_tmp = pd.read_csv(os.path.join(folder, folder_lifecycle, merged_res))\n",
    "            df_test.loc[len(df_test)] = preprocess_seq(df_tmp, label, False)\n",
    "            df_train.loc[len(df_train)] = preprocess_seq(df_tmp, label, True)\n",
    "            \n",
    "            df_show = df_tmp.loc[((df_tmp['TIMESTAMP'] >= t_start) & (df_tmp['TIMESTAMP'] <= t_end)), 'label']\n",
    "            print(f'{merged_res}: start:{t_start} end:{t_end} len:{len(df_show)}')\n",
    "            \n",
    "            if 'A+L+T' in merged_res:\n",
    "                df_pattern.loc[len(df_pattern)] = preprocess_seq(df_tmp, label, False)\n",
    "\n",
    "print(df_test.info)\n",
    "print(df_train.info)\n",
    "print(df_pattern.info)\n",
    "df_test.to_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset_test_original.csv'), encoding='utf-8', index=False)\n",
    "df_train.to_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset_train_original.csv'), encoding='utf-8', index=False)\n",
    "df_pattern.to_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_pattern.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sequence length: 2093\n",
      "label 0 total data: 91\n",
      "label 1 total data: 91\n",
      "label 2 total data: 91\n",
      "label 3 total data: 91\n",
      "label 4 total data: 91\n",
      "                                             lifecycle Label\n",
      "0    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     0\n",
      "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...     0\n",
      "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...     0\n",
      "4    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     0\n",
      "..                                                 ...   ...\n",
      "450  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     4\n",
      "451  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...     4\n",
      "452  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...     4\n",
      "453  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...     4\n",
      "454  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...     4\n",
      "\n",
      "[455 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "\n",
    "# data_type = 'train'\n",
    "data_type = 'test'\n",
    "df = pd.read_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset_'+data_type+'_original.csv'))\n",
    "\n",
    "times_generating = 12\n",
    "len_rand = 5\n",
    "\n",
    "\n",
    "df_new = pd.DataFrame(columns=['lifecycle', 'Label'])\n",
    "max_len = 0\n",
    "for i in range(times_generating):\n",
    "    for j, item in enumerate(df['lifecycle']):\n",
    "        list_new = []\n",
    "        lifecycle = ast.literal_eval(item)\n",
    "        index = 0\n",
    "        while index < len(lifecycle):\n",
    "            if lifecycle[index] != 0:\n",
    "                list_new.append(lifecycle[index])\n",
    "                index += 1\n",
    "            else:\n",
    "                index_new = index\n",
    "                while index_new < len(lifecycle) and lifecycle[index_new] == 0:\n",
    "                    index_new += 1\n",
    "                len_0 = index_new - index\n",
    "                num_rand = random.randint(max(0, len_0 - len_rand), len_0 + len_rand)\n",
    "                list_new.extend([0] * num_rand)\n",
    "                index = index_new\n",
    "\n",
    "        max_len = max(max_len, len(list_new))\n",
    "        # print(len(lifecycle))\n",
    "        # print(len(list_new))\n",
    "        # print('----')\n",
    "        df_new.loc[len(df_new)] = pd.Series([list_new, df['Label'][j]], index=['lifecycle', 'Label'])\n",
    "\n",
    "df = pd.concat([df, df_new], ignore_index=True)\n",
    "df.to_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset_'+data_type+'.csv'), encoding='utf-8', index=False)\n",
    "\n",
    "print(f'max sequence length: {max_len}')\n",
    "for label in sorted(df['Label'].unique()):\n",
    "    len_label = len(df[df['Label'] == label])\n",
    "    print(f'label {label} total data: {len_label}')\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Techniques (LCS DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifecycle 0 and lifecycle 1:\n",
      "target:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1, 11, 1, 13, 15, 13]\n",
      "seq:\n",
      "[1, 14, 1, 14, 1, 14, 1, 14, 1, 14, 4, 2, 4, 1, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4, 1, 4, 2, 1, 14, 1, 14]\n",
      "common techs:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1]\n",
      "\n",
      "lifecycle 0 and lifecycle 2:\n",
      "target:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1, 11, 1, 13, 15, 13]\n",
      "seq:\n",
      "[1, 14, 1, 2, 4, 13, 1, 13, 1, 13, 1, 13, 2, 1, 13, 1, 13, 1, 13, 1, 13, 8, 13, 1, 14, 13, 1, 13, 1, 13, 1, 13, 1, 13, 15, 13]\n",
      "common techs:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1, 1, 13, 15, 13]\n",
      "\n",
      "lifecycle 0 and lifecycle 3:\n",
      "target:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1, 11, 1, 13, 15, 13]\n",
      "seq:\n",
      "[1, 14, 1, 2, 1, 4, 2, 1, 4, 1, 4, 1, 4, 1, 14, 1, 2, 1, 14, 1]\n",
      "common techs:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1]\n",
      "\n",
      "lifecycle 0 and lifecycle 4:\n",
      "target:\n",
      "[1, 14, 1, 4, 1, 2, 14, 1, 11, 1, 13, 15, 13]\n",
      "seq:\n",
      "[1, 8, 14, 2, 4, 2, 4, 2, 4, 2, 4, 14, 15, 17, 13, 1, 13, 1, 13]\n",
      "common techs:\n",
      "[1, 14, 4, 2, 14, 1, 1, 13]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from itertools import groupby\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset_original.csv'))\n",
    "target_label = 0\n",
    "remaining_labels = [1, 2, 3, 4]\n",
    "target = df[df['Label'] == target_label].values[0][0]\n",
    "df_remain = df[df['Label'] != target_label]\n",
    "res = {}\n",
    "\n",
    "\n",
    "def preprocess(seq):\n",
    "    '''\n",
    "    seq: str type, but content is list\n",
    "    '''\n",
    "    seq = ast.literal_eval(seq)\n",
    "    seq = [value for value in seq if value != 0]\n",
    "    seq = [key for key, _group in groupby(seq)]\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def lcs(X, Y):\n",
    "    '''\n",
    "    X, Y: both are list\n",
    "    '''\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    L = [[0] * (n + 1) for i in range(m + 1)]\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if X[i - 1] == Y[j - 1]:\n",
    "                L[i][j] = L[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
    "    \n",
    "    index = L[m][n]\n",
    "    common_seq = [None] * index\n",
    "    i = m\n",
    "    j = n\n",
    "    while i > 0 and j > 0:\n",
    "        if X[i - 1] == Y[j - 1]:\n",
    "            common_seq[index - 1] = X[i - 1]\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            index -= 1\n",
    "        elif L[i - 1][j] > L[i][j - 1]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "    \n",
    "    return common_seq\n",
    "\n",
    "\n",
    "target = preprocess(target)\n",
    "for seq, label in df_remain.values:\n",
    "    seq = preprocess(seq)\n",
    "    \n",
    "    common_techs = lcs(seq, target)\n",
    "    print(f'lifecycle {target_label} and lifecycle {label}:')\n",
    "    print(f'target:\\n{target}')\n",
    "    print(f'seq:\\n{seq}')\n",
    "    print(f'common techs:\\n{common_techs}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Distance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                               lifecycle  Label\n",
      "0     [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...      0\n",
      "1     [1, 0, 0, 1, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 14...      1\n",
      "2     [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...      2\n",
      "3     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...      3\n",
      "4     [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...      4\n",
      "...                                                 ...    ...\n",
      "2000  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...      0\n",
      "2001  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 14,...      1\n",
      "2002  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...      2\n",
      "2003  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      3\n",
      "2004  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...      4\n",
      "\n",
      "[2005 rows x 2 columns]>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_similarity() missing 1 required positional argument: 'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m similarity\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X)):\n\u001b[1;32m---> 42\u001b[0m     get_similarity(X[i],)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_similarity() missing 1 required positional argument: 'B'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_dataset.csv'))\n",
    "pattern = pd.read_csv(os.path.join(folder, folder_lifecycle, 'lifecycle_pattern.csv'))\n",
    "print(df.info)\n",
    "\n",
    "\n",
    "X = df['lifecycle']\n",
    "X = X.to_numpy()\n",
    "y = df['Label']\n",
    "y = y.to_numpy()\n",
    "y = y.reshape(-1)\n",
    "\n",
    "\n",
    "def get_similarity(A, B):\n",
    "    '''\n",
    "    use levenshtein distance to compute the similarity\n",
    "    '''\n",
    "    m = len(A)\n",
    "    n = len(B)\n",
    "    D = [[0] * (n + 1) for i in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        D[0][j] = j\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, m + 1):\n",
    "            if A[i - 1] == B[j - 1]:\n",
    "                D[i][j] = D[i - 1][j - 1]\n",
    "            else:\n",
    "                D[i][j] = min(D[i - 1][j] + 1, D[i][j - 1] + 1, D[i - 1][j - 1] + 1)\n",
    "\n",
    "    similarity = 1.0 - (float(D[m][n]) / float(max(len(A), len(B))))\n",
    "\n",
    "    return similarity\n",
    "\n",
    "for i in range(len(X)):\n",
    "    get_similarity(X[i],)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 approaches comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m width \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[1;32m----> 5\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(models))\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[0;32m      7\u001b[0m plt\u001b[39m.\u001b[39mbar(x, result[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], width, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "evaluation = []\n",
    "evaluation[name]['accuracy'].append(accuracy_score(y_test, y_hat,))\n",
    "evaluation[name]['precision'].append(precision_score(y_test, y_hat, average='weighted',zero_division=0))\n",
    "evaluation[name]['recall'].append(recall_score(y_test, y_hat, average='weighted', zero_division=0))\n",
    "evaluation[name]['f1_score'].append(f1_score(y_test, y_hat, average='weighted', zero_division=0))\n",
    "\n",
    "def round_off(value, n):\n",
    "    return math.floor(value * (10 ** n)) / float(10 ** n) \n",
    "\n",
    "models = [name.replace('_', '\\n') for name in evaluation]\n",
    "result = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "for name in evaluation:\n",
    "    for key, value in evaluation[name].items():\n",
    "        result[key].append(round_off(mean(value), 3))\n",
    "        \n",
    "        if name == 'Bi-GRU':\n",
    "            print(f'metric {key}: {round_off(mean(value), 3)}')\n",
    "\n",
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(x, result['accuracy'], width, label='accuracy')\n",
    "plt.bar(x+width, result['precision'], width, label='precision')\n",
    "plt.bar(x+2*width, result['recall'], width, label='recall')\n",
    "bar = plt.bar(x+3*width, result['f1_score'], width, label='f1_score')\n",
    "plt.bar_label(bar, label_type='edge', fontsize=20)\n",
    "plt.title('Approaches Performance Comparison', fontsize=30)\n",
    "plt.xticks(x+1.5*width, models)\n",
    "plt.xlabel('model', fontsize=25)\n",
    "plt.ylabel('value', fontsize=22)\n",
    "plt.rcParams.update({\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 16,\n",
    "})\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=20)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acbeb801ef841938b72c15cd1756d069d76df8d13059b274a4de3d770d945625"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
