{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLModel(folder=r'Logs/test', train_filename='UNSW_NB15_training-set.csv', test_filename='UNSW_NB15_testing-set.csv', \\\n",
    "            label_field='label', data_source=''):\n",
    "    # load dataset\n",
    "    X_train, y_train = loadDataset2Train(folder, train_filename, label_field)\n",
    "    X_test, y_test = loadDataset2Train(folder, test_filename, label_field)\n",
    "    # get model list\n",
    "    models = define_models()\n",
    "\n",
    "    accuracies = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    my_f1_scores = {}\n",
    "    total_accuracies = 0\n",
    "    for name, model in models.items():\n",
    "        print('training model {}...........................'.format(name))\n",
    "        history = model.fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        # evaluate predictions\n",
    "        accuracies[name] = accuracy_score(y_test, y_hat)\n",
    "        precisions[name] = precision_score(y_test, y_hat)\n",
    "        recalls[name] = recall_score(y_test, y_hat)\n",
    "        my_f1_scores[name] = f1_score(y_test, y_hat)\n",
    "\n",
    "    accuracies['average'] = sum(accuracies.values()) / len(accuracies)\n",
    "    precisions['average'] = sum(precisions.values()) / len(precisions)\n",
    "    recalls['average'] = sum(recalls.values()) / len(recalls)\n",
    "    my_f1_scores['average'] = sum(my_f1_scores.values()) / len(my_f1_scores)\n",
    "\n",
    "    print(accuracies)\n",
    "    print(precisions)\n",
    "    print(recalls)\n",
    "    print(my_f1_scores)\n",
    "\n",
    "    # plot feature importance\n",
    "    pyplot.bar(*zip(*accuracies.items()))\n",
    "    # for index, data in enumerate(accuracies):\n",
    "    #    pyplot.text(x=index , y=data+1 , s=str(1) , fontdict=dict(fontsize=20))\n",
    "    # pyplot.show()\n",
    "\n",
    "    with open(r'Logs/Fig/mydataset/accuracy/{0}_accuracy.txt'.format(data_source), \"w+\") as fw:\n",
    "        json.dump(accuracies, fw)\n",
    "    with open(r'Logs/Fig/mydataset/accuracy/{0}_precision.txt'.format(data_source), \"w+\") as fw:\n",
    "        json.dump(precisions, fw)\n",
    "    with open(r'Logs/Fig/mydataset/accuracy/{0}_recall.txt'.format(data_source), \"w+\") as fw:\n",
    "        json.dump(recalls, fw)\n",
    "    with open(r'Logs/Fig/mydataset/accuracy/{0}_f1score.txt'.format(data_source), \"w+\") as fw:\n",
    "        json.dump(my_f1_scores, fw)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
