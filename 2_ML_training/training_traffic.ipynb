{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "# ML model parts\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MLModel(folder=r'Logs/test', train_filename='UNSW_NB15_training-set.csv', test_filename='UNSW_NB15_testing-set.csv', \\\n",
    "#             label_field='label', data_source=''):\n",
    "# load dataset\n",
    "X_train, y_train = loadDataset2Train(folder, train_filename, label_field)\n",
    "X_test, y_test = loadDataset2Train(folder, test_filename, label_field)\n",
    "# get model list\n",
    "models = define_models()\n",
    "\n",
    "accuracies = {}\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "my_f1_scores = {}\n",
    "total_accuracies = 0\n",
    "for name, model in models.items():\n",
    "    print('training model {}...........................'.format(name))\n",
    "    history = model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    # evaluate predictions\n",
    "    accuracies[name] = accuracy_score(y_test, y_hat)\n",
    "    precisions[name] = precision_score(y_test, y_hat)\n",
    "    recalls[name] = recall_score(y_test, y_hat)\n",
    "    my_f1_scores[name] = f1_score(y_test, y_hat)\n",
    "\n",
    "accuracies['average'] = sum(accuracies.values()) / len(accuracies)\n",
    "precisions['average'] = sum(precisions.values()) / len(precisions)\n",
    "recalls['average'] = sum(recalls.values()) / len(recalls)\n",
    "my_f1_scores['average'] = sum(my_f1_scores.values()) / len(my_f1_scores)\n",
    "\n",
    "print(accuracies)\n",
    "print(precisions)\n",
    "print(recalls)\n",
    "print(my_f1_scores)\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar(*zip(*accuracies.items()))\n",
    "# for index, data in enumerate(accuracies):\n",
    "#    pyplot.text(x=index , y=data+1 , s=str(1) , fontdict=dict(fontsize=20))\n",
    "# pyplot.show()\n",
    "\n",
    "with open(r'Logs/Fig/mydataset/accuracy/{0}_accuracy.txt'.format(data_source), \"w+\") as fw:\n",
    "    json.dump(accuracies, fw)\n",
    "with open(r'Logs/Fig/mydataset/accuracy/{0}_precision.txt'.format(data_source), \"w+\") as fw:\n",
    "    json.dump(precisions, fw)\n",
    "with open(r'Logs/Fig/mydataset/accuracy/{0}_recall.txt'.format(data_source), \"w+\") as fw:\n",
    "    json.dump(recalls, fw)\n",
    "with open(r'Logs/Fig/mydataset/accuracy/{0}_f1score.txt'.format(data_source), \"w+\") as fw:\n",
    "    json.dump(my_f1_scores, fw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('multistage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e316b1ad1bb7084be8c3b1650f7484094eadbbf4b3451c2488d40589d31287db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
